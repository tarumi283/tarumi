{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMPArPSbDdHFY06kzuzlKf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarumi283/tarumi/blob/main/file_parser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDwmdKQspiAj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from CosinorPy import cosinor\n",
        "import re\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    file_name\n",
        "    trim: cut the data to keep only timepoints between t_start and t_end. t_start and t_end are read from the first line of the sheet. If their values are -1, -1, no data is removed\n",
        "    diff: use the differences between two subsequent data as a measurement value (for lumicycle)\n",
        "    rescale_x: when multiple measurement are available per timepoint distribute the data uniformly within 1 hour (for lumicycle)\n",
        "    individual: separate the multiple iterations of the same measurement (for lumicycle)\n",
        "\"\"\"\n",
        "    \n",
        "def read_excel(file_name, trim=False, diff=False, rescale_x=False, independent=True, remove_outliers=False, skip_tabs=False):\n",
        "    names = []\n",
        "     \n",
        "        \n",
        "    df = pd.DataFrame(columns=['x', 'y', 'test'], dtype=float)\n",
        "        \n",
        "        \n",
        "    xls_file = pd.ExcelFile(file_name)\n",
        "    for sheet_idx, sheet_name in enumerate(xls_file.sheet_names):\n",
        "            \n",
        "        if skip_tabs and sheet_idx < skip_tabs:    \n",
        "            continue\n",
        "            \n",
        "        \n",
        "        sheet = xls_file.parse(sheet_name, header=None)\n",
        "        #print(sheet_name)\n",
        "            \n",
        "        M = np.array(sheet)\n",
        "            \n",
        "        # get x and y\n",
        "        x = M[:,0].astype(float)\n",
        "        y = M[:,1].astype(float)\n",
        "            \n",
        "                       \n",
        "        \"\"\"\n",
        "            nans, nans, nas\n",
        "        \"\"\"          \n",
        "        # remove nans from time steps\n",
        "        y = y[np.argwhere(~np.isnan(x))[:,0]]\n",
        "        x = x[np.argwhere(~np.isnan(x))[:,0]]\n",
        "            \n",
        "     \n",
        "        if trim:\n",
        "            x,y = trim_data(x,y)\n",
        "            \n",
        "        if diff:\n",
        "            x,y = differentiate(x,y)                \n",
        "\n",
        "        if rescale_x:\n",
        "            x,y = rescale_times(x,y)\n",
        "                                        \n",
        "                \n",
        "        \"\"\"\n",
        "            nans, nans, nas\n",
        "        \"\"\"\n",
        "        # remove nans from measurement data\n",
        "        x = x[np.argwhere(~np.isnan(y))[:,0]]\n",
        "        y = y[np.argwhere(~np.isnan(y))[:,0]]\n",
        "            \n",
        "        if remove_outliers:\n",
        "            x,y = remove_outliers_f(x,y)\n",
        "\n",
        "        if independent:\n",
        "            df_measurement = pd.DataFrame({'x':x, 'y':y})\n",
        "            df_measurement['test'] = sheet_name\n",
        "            names.append(sheet_name)\n",
        "            df = df.append(df_measurement)                \n",
        "            \n",
        "        else:\n",
        "            #idxs = np.argwhere(x > np.append(x[1:], [0]))[:-1] + 1\n",
        "            idxs = np.argwhere(x > np.append(x[1:], [0])) + 1\n",
        "            idxs = np.append([0], idxs)\n",
        "            for i in range(len(idxs)-1):\n",
        "                df_measurement = pd.DataFrame({'x':x[idxs[i]:idxs[i+1]], 'y':y[idxs[i]:idxs[i+1]]})\n",
        "                df_measurement['test'] = sheet_name + '_rep' + str(i+1) \n",
        "                names.append(sheet_name + '_rep' + str(i+1))\n",
        "                df = df.append(df_measurement)             \n",
        "            \n",
        "                        \n",
        "\n",
        "            \n",
        "    return df\n",
        "\n",
        "def generate_test_data_group_random(N, name_prefix = \"\", characterize_data = False, amplitude=1, **kwargs):\n",
        "    df = pd.DataFrame(columns=['test','x','y'], dtype=float)\n",
        "    if characterize_data:\n",
        "        df_params = pd.DataFrame(dtype=float)\n",
        "\n",
        "    if not name_prefix:\n",
        "        name_prefix = \"test\"\n",
        "\n",
        "    for i in range(N):\n",
        "        name = f\"{name_prefix}_{i}\"\n",
        "        phases = [2*np.pi*np.random.random(), 2*np.pi*np.random.random(), 2*np.pi*np.random.random()]\n",
        "        amplitudes = [amplitude,0.5*np.random.random(),0.5*np.random.random()]\n",
        "\n",
        "        if characterize_data:\n",
        "            df2, rhythm_params = generate_test_data(name=name, characterize_data = True, phase = phases, amplitudes = amplitudes,  **kwargs)\n",
        "            df = df.append(df2, ignore_index=True)\n",
        "            df_params = df_params.append(rhythm_params, ignore_index=True, sort=False)\n",
        "        else:\n",
        "            df2 = generate_test_data(name=name, phase = phases, amplitudes = amplitudes, **kwargs)\n",
        "            df = df.append(df2, ignore_index=True)\n",
        "\n",
        "    if characterize_data:\n",
        "        return df, df_params\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "\n",
        "\n",
        "def generate_test_data_group(N, name_prefix = \"\", characterize_data = False, **kwargs):\n",
        "    df = pd.DataFrame(columns=['test','x','y'], dtype=float)\n",
        "    if characterize_data:\n",
        "        df_params = pd.DataFrame(dtype=float)\n",
        "\n",
        "    if not name_prefix:\n",
        "        name_prefix = \"test\"\n",
        "\n",
        "    for i in range(N):\n",
        "        name = f\"{name_prefix}_{i}\"\n",
        "       \n",
        "        if characterize_data:\n",
        "            df2, rhythm_params = generate_test_data(name=name, characterize_data = True, **kwargs)\n",
        "            df = df.append(df2, ignore_index=True)\n",
        "            df_params = df_params.append(rhythm_params, ignore_index=True, sort=False)\n",
        "        else:\n",
        "            df2 = generate_test_data(name=name, **kwargs)\n",
        "            df = df.append(df2, ignore_index=True)\n",
        "\n",
        "    if characterize_data:\n",
        "        return df, df_params\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "def generate_test_data(n_components=1, period = 24, amplitudes = None, baseline = 0, lin_comp = 0, amplification = 0, phase = 0, min_time = 0, max_time = 48, time_step = 2, replicates = 1, independent = True, name=\"test\", noise = 0, noise_simple = 1, characterize_data=False):\n",
        "    df = pd.DataFrame(columns=['test','x','y'], dtype=float)\n",
        "    x = np.arange(min_time, max_time+time_step, time_step)\n",
        "\n",
        "    if amplitudes==None:\n",
        "        amplitudes = np.array([1,1/2,1/3,1/4])\n",
        "   \n",
        "    periods = np.array([period, period/2, period/3, period/4])\n",
        "   \n",
        "    if (type(phase) == int) or (type(phase)==float):\n",
        "        phases = np.array([phase, phase, phase, phase])\n",
        "    else:        \n",
        "        phases = np.array(phase)    \n",
        "\n",
        "    for i in range(replicates):\n",
        "        y = np.zeros(len(x))\n",
        "        \n",
        "        for j in range(n_components):\n",
        "            y += amplitudes[j] * np.cos((x/periods[j])*np.pi*2 + phases[j])\n",
        "   \n",
        "        # if amplification < 0: oscillations are damped with time\n",
        "        # if amplification > 0: oscillations are amplified with time\n",
        "        # if amplification == 0: oscillations are sustained        \n",
        "        y *= np.exp(amplification*x)\n",
        "        \n",
        "        # if lin_comp != 0: baseline is rising/decreasing with time\n",
        "        y +=  lin_comp*x\n",
        "        \n",
        "        y += baseline\n",
        "        \n",
        "        if independent:\n",
        "            test = name\n",
        "        else:\n",
        "            test = name + \"_rep\" + str(i+1)\n",
        "        mu = 0\n",
        "        sigma = noise\n",
        "            \n",
        "        NOISE = np.random.normal(mu, sigma, y.shape) \n",
        "        if noise_simple:\n",
        "            y += NOISE\n",
        "        else:\n",
        "            # mutliplicative noise\n",
        "            # sigma from 0 to 1; \n",
        "            # 0 ... no noise\n",
        "            # 1 ... maximal noise\n",
        "            \"\"\"\n",
        "            mu = 1\n",
        "            sigma = noise            \n",
        "            y *= np.random.normal(mu, sigma, y.shape) \n",
        "            \"\"\"\n",
        "            y *= (1 + NOISE)\n",
        "        \n",
        "        df2 = pd.DataFrame(columns=['test','x','y'], dtype=float)\n",
        "        df2['x'] = x\n",
        "        df2['y'] = y\n",
        "        df2['test'] = test\n",
        "        df = pd.concat([df, df2])\n",
        "    df['x'] = df['x'].astype(float)\n",
        "    df['y'] = df['y'].astype(float)\n",
        "\n",
        "    if characterize_data:\n",
        "        \n",
        "        X_eval = np.linspace(0, 2*period, 1000)\n",
        "        Y_eval = np.zeros(len(X_eval))\n",
        "        for j in range(n_components):\n",
        "            Y_eval += amplitudes[j] * np.cos((X_eval/periods[j])*np.pi*2 + phases[j])\n",
        "        Y_eval += baseline\n",
        "        rhythm_params = cosinor.evaluate_rhythm_params(X_eval, Y_eval, period=period)\n",
        "\n",
        "        rhythm_params['lin_comp'] = lin_comp\n",
        "        rhythm_params['amplification'] = amplification\n",
        "        rhythm_params['period'] = period\n",
        "        rhythm_params['test'] = test\n",
        "\n",
        "        return df, rhythm_params\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "def read_csv(file_name, sep=\"\\t\"):\n",
        "    \n",
        "    df1 = pd.read_csv(file_name, sep=sep)\n",
        "\n",
        "    try:\n",
        "        header = np.array(list(map(lambda s: re.sub('[^0-9_]','', s), df1.columns[1:])))\n",
        "        reps = int(header[-1].split('_')[1])\n",
        "        \n",
        "        t1 = int(header[0].split(\"_\")[0])\n",
        "        t2 = int(header[reps].split(\"_\")[0])\n",
        "        dt = t2-t1\n",
        "        \n",
        "        max_time = int(header[-1].split(\"_\")[0])\n",
        "        \n",
        "        measurements = max_time//dt\n",
        "                \n",
        "        shuffle = np.array([(np.arange(0,measurements*reps+1,reps))+i for i in range(reps)]).flatten()\n",
        "                \n",
        "        x = list(map(lambda t: int(t.split('_')[0]), header[shuffle]))\n",
        "    except:\n",
        "        reps = 1\n",
        "        shuffle = np.arange(0,len(df1.columns)-1)\n",
        "        x = list(map(lambda s: int(re.sub('[^0-9]','', s)), df1.columns[1:]))\n",
        "\n",
        "\n",
        "    Y = df1.iloc[:,shuffle+1].values\n",
        "    names = df1.iloc[:,0].values\n",
        "\n",
        "    df2 = pd.DataFrame(columns=['test','x','y'], dtype=float)\n",
        "    for y, name in zip(Y, names):\n",
        "        df_tmp = pd.DataFrame(columns=['test','x','y'], dtype=float)\n",
        "        df_tmp['x'] = x\n",
        "        df_tmp['y'] = y\n",
        "        df_tmp['test'] = name\n",
        "\n",
        "        df2 = pd.concat([df2, df_tmp])\n",
        "\n",
        "    df2['x'] = df2['x'].astype(float)\n",
        "    df2['y'] = df2['y'].astype(float)\n",
        "\n",
        "    df2 = df2.dropna()\n",
        "\n",
        "    return df2\n",
        "\n",
        "def export(df, file_name, independent = True):\n",
        "    tests = df.test.unique()\n",
        "    if not independent:\n",
        "        tests = list(set(map(lambda s:('_').join(s.split('_')[:-1]), tests)))\n",
        "        tests.sort()\n",
        "    \n",
        "    with pd.ExcelWriter(file_name) as writer:  \n",
        "        for test in tests:\n",
        "            if independent:\n",
        "                df[df.test == test][['x','y']].to_excel(writer, sheet_name=test, header=False, index=False)        \n",
        "            else:\n",
        "                df[df.test.str.startswith(test)][['x','y']].to_excel(writer, sheet_name=test, header=False, index=False)        \n",
        "                \n",
        "\n",
        "\n",
        "def export_csv(df, file_name, individual=False):\n",
        "    export_JTK(df, file_name, individual=individual)\n",
        "\n",
        "\"\"\"\n",
        "    EXPORT FOR JTK\n",
        "\"\"\"        \n",
        "# descriptor: add additional descriptor file\n",
        "# names: export only these names\n",
        "# individual: rescale measurements\n",
        "def export_JTK(df, file_name, descriptor = \"\", names = [], individual=False):\n",
        "    if not names:\n",
        "        names = df.test.unique()\n",
        "    elif type(names) == str:\n",
        "        names = [names]\n",
        "        \n",
        "    df_export = df[df.test.isin(names)].copy()\n",
        "        \n",
        "    df_export['x'] = df_export['x'].map(int)\n",
        "\n",
        "    # merge multiple equal timepoints for a single measurement: only if individual!!!\n",
        "    if individual:\n",
        "        for name in names:\n",
        "            df_name = df_export[df_export.test == name]\n",
        "            x,y = np.array(df_name.x), np.array(df_name.y)\n",
        "            x_unique = np.unique(x)\n",
        "            y_unique = np.zeros(len(x_unique))\n",
        "            for i in range(len(x_unique)):\n",
        "                y_unique[i] = np.mean(y[x == x_unique[i]])\n",
        "                \n",
        "            df_export = df_export[df_export.test != name]\n",
        "            df_tmp = pd.DataFrame({'x':x_unique, 'y':y_unique})\n",
        "            df_tmp['test'] = name\n",
        "            df_export = df_export.append(df_tmp, ignore_index=True)\n",
        "      \n",
        "    reps = 0\n",
        "        \n",
        "    for name in names:\n",
        "        x = np.array(df_export[df_export.test == name].x)\n",
        "        r = sum(x[1:] - x[:-1] < 0)+1\n",
        "        if reps < r:\n",
        "            reps = r\n",
        "                \n",
        "        \n",
        "        \n",
        "    mintime = df_export['x'].min() \n",
        "    maxtime = df_export['x'].max()\n",
        "    timestep = np.argmax(np.bincount(abs(np.array(df_export.x)[1:] - np.array(df_export.x)[:-1])))\n",
        "    samples_in_one = (maxtime-mintime)//timestep + 1\n",
        "               \n",
        "    columns = [\"gene\"] + [\"T\"+str(i)+\"_Rep\"+str(j+1) for i in range(mintime, maxtime+1,timestep) for j in range(0,reps)]\n",
        "    df = pd.DataFrame(columns=columns, dtype=float)\n",
        "        \n",
        "    x_full = np.arange(mintime, maxtime+1, timestep)\n",
        "    x_fuller = np.array(list(range(mintime, maxtime+1, timestep)) * reps)\n",
        "    y_full = np.zeros(len(x_full) * reps)\n",
        "        \n",
        "        \n",
        "        \n",
        "    for name in names:                          \n",
        "        x,y = np.array(df_export[df_export.test == name].x), np.array(df_export[df_export.test == name].y)\n",
        "                        \n",
        "        #idxs = np.where(x[1:] - x[:-1] < 0)\n",
        "        y_full[:] = np.nan\n",
        "        \n",
        "        for t in x_full:\n",
        "            values = y[x == t]\n",
        "            locs = np.where(t==x_fuller)[0]\n",
        "            locs = locs[:len(values)]\n",
        "            y_full[locs] = values\n",
        "            \n",
        "        \"\"\"\n",
        "        for r, i in enumerate(idxs):\n",
        "            for j in range(samples_in_one):\n",
        "                old_loc = \n",
        "                new_loc = samples_in_one*r + j\n",
        "        \"\"\"        \n",
        "                    \n",
        "                    \n",
        "                    \n",
        "                    \n",
        "            \n",
        "        sorted_values = []\n",
        "        for i in range(samples_in_one):\n",
        "            for j in range(reps):\n",
        "                #print(i,j, i + (samples_in_one) * j)\n",
        "                sorted_values.append(y_full[i + (samples_in_one) * j])\n",
        "        df.loc[df.shape[0]] = [name] + sorted_values\n",
        "        \n",
        "    df.to_csv(file_name, sep=\"\\t\", index=False, na_rep='NA')\n",
        "        \n",
        "    if descriptor:\n",
        "        f = open(descriptor, 'w')\n",
        "        f.write(str(samples_in_one) + \"\\t\")\n",
        "        f.write(str(reps) + \"\\t\")\n",
        "        f.write(str(timestep) + \"\\n\")\n",
        "        f.close()\n",
        "\n",
        "\"\"\"\n",
        "    TRIM TRIM TRIM\n",
        "\"\"\"            \n",
        "def trim_data(x,y):\n",
        "    t_start = x[0]\n",
        "    t_end = y[0]\n",
        "    x = x[1:]\n",
        "    y = y[1:]\n",
        "        \n",
        "    if t_start != -1:\n",
        "        y = y[np.logical_and(x >= t_start, x <= t_end)]\n",
        "        x = x[np.logical_and(x >= t_start, x <= t_end)]\n",
        "    \n",
        "    return x,y\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    DIFF DIFF DIFF\n",
        "\"\"\"            \n",
        "def differentiate(x, y):\n",
        "    # calculate the differentials\n",
        "    y[:-1] = y[1:] - y[:-1]\n",
        "    y = y[x <= np.append(x[1:], [0])]\n",
        "    x = x[x <= np.append(x[1:], [0])]\n",
        "    return x,y\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "\"\"\"\n",
        "    RESCALE RESCALE RESCALE\n",
        "\"\"\"\n",
        "def rescale_times(x, y):\n",
        "    i = 0\n",
        "    while i < len(x):\n",
        "        j = i + 1\n",
        "        while (j < len(x)) and (x[j] == x[i]):\n",
        "            j = j + 1\n",
        "               \n",
        "\n",
        "        n_same = j - i\n",
        "\n",
        "        for k in range(i+1,j):\n",
        "            x[k] = x[k] + (1/n_same)*(k-i)                   \n",
        "        i = j\n",
        "    \n",
        "    return x,y\n",
        "    \n",
        "def remove_outliers_f(x, y):\n",
        "    m, s = np.mean(y), np.std(y)        \n",
        "    idxs = np.logical_not(np.logical_or(y > m + 3*s, y < m - 3*s))\n",
        "    #print(x[np.logical_not(idxs)], y[np.logical_not(idxs)])\n",
        "    return x[idxs], y[idxs]\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "RESCALE RESCALE RESCALE\n",
        "\"\"\"\n",
        "def rescale_to_median(x, y):\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "\n",
        "    i = 0\n",
        "    while i < len(x):\n",
        "        j = i + 1\n",
        "        while (j < len(x)) and (x[j] == x[i]):\n",
        "            j = j + 1\n",
        "           \n",
        "        new_x.append(x[i])\n",
        "        new_y.append(np.median(y[i:j]))\n",
        "                        \n",
        "        i = j\n",
        "\n",
        "    return np.array(new_x),np.array(new_y)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "EXPORT FOR COSINOR 2\n",
        "\"\"\"  \n",
        "def export_cosinor2(input_file_name, output_file_name, period = 24, trim=False, diff=False, remove_outliers=False, rescale_median = False, remove_lin_comp = False):        \n",
        "    outputs = []\n",
        "\n",
        "    xls_file = pd.ExcelFile(input_file_name)\n",
        "    for sheet_name in xls_file.sheet_names:\n",
        "\n",
        "        sheet = xls_file.parse(sheet_name, header=None)\n",
        "        #print(sheet_name)\n",
        "\n",
        "        M = np.array(sheet)\n",
        "\n",
        "        # get x and y\n",
        "        x = M[:,0].astype(float)\n",
        "        y = M[:,1].astype(float)\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        nans, nans, nas\n",
        "        \"\"\"          \n",
        "        # remove nans from time steps\n",
        "        y = y[np.argwhere(~np.isnan(x))[:,0]]\n",
        "        x = x[np.argwhere(~np.isnan(x))[:,0]]\n",
        "\n",
        "\n",
        "        if trim:\n",
        "           x,y = trim_data(x,y)\n",
        "\n",
        "        if diff:\n",
        "           x,y = differentiate(x,y)                \n",
        "\n",
        "        if remove_outliers:\n",
        "            x,y = remove_outliers_f(x,y)\n",
        "\n",
        "        if rescale_median:\n",
        "            x,y = rescale_to_median(x,y)\n",
        "            min_x = min(x)\n",
        "            max_x = max(x)\n",
        "            full_x = np.arange(min_x, max_x+1)\n",
        "        else:\n",
        "            x,y = rescale_times(x,y)\n",
        "            full_x = np.sort(np.unique(x))\n",
        "                    \n",
        "                    \n",
        "        df = pd.DataFrame()\n",
        "        df['time'] = full_x\n",
        "\n",
        "        idxs = np.argwhere(x > np.append(x[1:], [0])) + 1\n",
        "        idxs = np.append([0], idxs)\n",
        "        \n",
        "        \n",
        "        \n",
        "        for i in range(len(idxs)-1):\n",
        "                curr_x = x[idxs[i]:idxs[i+1]]\n",
        "                curr_y = y[idxs[i]:idxs[i+1]]\n",
        "                \n",
        "                if remove_lin_comp:\n",
        "                    curr_x, curr_y = cosinor.remove_lin_comp(curr_x, curr_y, n_components = 1, period = period)\n",
        "                \n",
        "                full_y = np.zeros(len(full_x))\n",
        "                full_y[:] = np.nan\n",
        "                for cx in curr_x:                                      \n",
        "                    full_y[full_x == cx] = curr_y[curr_x == cx]                                \n",
        "                df['Subject '+str(i+1)] = full_y\n",
        "        outputs.append((df, sheet_name))\n",
        "\n",
        "    with pd.ExcelWriter(output_file_name) as writer:  \n",
        "        for df, sheet_name in outputs:            \n",
        "            #df.to_excel(writer, sheet_name=sheet_name, index=False)         \n",
        "            df.transpose().to_excel(writer, sheet_name=sheet_name, header=False)         \n",
        "            #df.transpose().to_excel(writer, sheet_name=sheet_name, index=False,header=False)         \n",
        "        "
      ]
    }
  ]
}